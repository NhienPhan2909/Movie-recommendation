{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c038390e",
   "metadata": {},
   "source": [
    "1. SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b73b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "# Use movielens-100K\n",
    "data = Dataset.load_builtin(\"ml-100k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69186025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "trainset, testset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c525447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in trainset:  943\n",
      "Number of items in trainset:  1655\n",
      "Number of users in testset:  943\n",
      "Number of items in testset:  1410\n"
     ]
    }
   ],
   "source": [
    "trainset_users = set(trainset.all_users())\n",
    "trainset_items = set(trainset.all_items())\n",
    "testset_users = set(testset[x][0] for x in range(len(testset)))\n",
    "testset_items = set(testset[x][1] for x in range(len(testset)))\n",
    "\n",
    "# Print the number of unique user IDs and item IDs in the trainset and testset\n",
    "print(\"Number of users in trainset: \", len(trainset_users))\n",
    "print(\"Number of items in trainset: \", len(trainset_items))\n",
    "print(\"Number of users in testset: \", len(testset_users))\n",
    "print(\"Number of items in testset: \", len(testset_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0700846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 0, item_id: 0, rating: 3.0\n",
      "user_id: 0, item_id: 207, rating: 5.0\n",
      "user_id: 0, item_id: 614, rating: 4.0\n",
      "user_id: 0, item_id: 668, rating: 5.0\n",
      "user_id: 0, item_id: 626, rating: 4.0\n"
     ]
    }
   ],
   "source": [
    "for i, (user_id, item_id, rating) in enumerate(trainset.all_ratings()):\n",
    "    print(f'user_id: {user_id}, item_id: {item_id}, rating: {rating}')\n",
    "    if i >= 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fea3201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 483, item_id: 313, rating: 2.0\n",
      "user_id: 22, item_id: 1000, rating: 3.0\n",
      "user_id: 793, item_id: 405, rating: 3.0\n",
      "user_id: 456, item_id: 222, rating: 2.0\n",
      "user_id: 896, item_id: 966, rating: 4.0\n"
     ]
    }
   ],
   "source": [
    "for i, (user_id, item_id, rating) in enumerate(testset):\n",
    "    print(f'user_id: {user_id}, item_id: {item_id}, rating: {rating}')\n",
    "    if i >= 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f2dab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9299554607390046\n",
      "0.7313789386080696\n",
      "{'n_factors': 50, 'n_epochs': 20, 'lr_all': 0.006, 'reg_all': 0.03}\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_factors': [50, 100, 150], \"n_epochs\": [15, 20, 25], \"lr_all\": [0.002, 0.004, 0.006], \"reg_all\": [0.01, 0.02, 0.03]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=5)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE and MAE score\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_score[\"mae\"])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aaa0734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9261  0.9329  0.9332  0.9269  0.9320  0.9302  0.0031  \n",
      "MAE (testset)     0.7290  0.7346  0.7332  0.7285  0.7341  0.7319  0.0026  \n",
      "Fit time          0.80    0.86    0.86    0.84    0.84    0.84    0.02    \n",
      "Test time         0.15    0.20    0.14    0.19    0.12    0.16    0.03    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.92611778, 0.93289917, 0.93315091, 0.92685046, 0.9319569 ]),\n",
       " 'test_mae': array([0.72904509, 0.73459753, 0.73323626, 0.72851411, 0.7340828 ]),\n",
       " 'fit_time': (0.7966892719268799,\n",
       "  0.8596572875976562,\n",
       "  0.8594143390655518,\n",
       "  0.8435530662536621,\n",
       "  0.8435530662536621),\n",
       " 'test_time': (0.14855623245239258,\n",
       "  0.20307588577270508,\n",
       "  0.14059185981750488,\n",
       "  0.1874549388885498,\n",
       "  0.1249699592590332)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "svd_algo = SVD(n_factors=50, n_epochs=25, lr_all=0.006, reg_all=0.03)\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(svd_algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c839610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9300\n",
      "MAE:  0.7326\n",
      "Running time:  1.0506892204284668\n"
     ]
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "import time\n",
    "start_time = time.time()\n",
    "svd_algo.fit(trainset)\n",
    "# Test the algorithm on the test set\n",
    "svd_predict = svd_algo.test(testset)\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute and print the RMSE and MAE scores\n",
    "rmse = accuracy.rmse(svd_predict)\n",
    "mae = accuracy.mae(svd_predict)\n",
    "print ('Running time: ', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74871474",
   "metadata": {},
   "source": [
    "2. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1fc9bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.5188  1.5238  1.5096  1.5156  1.5321  1.5200  0.0076  \n",
      "MAE (testset)     1.2200  1.2216  1.2156  1.2156  1.2285  1.2203  0.0048  \n",
      "Fit time          0.08    0.09    0.15    0.10    0.14    0.11    0.03    \n",
      "Test time         0.15    0.09    0.13    0.09    0.15    0.12    0.03    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.51884098, 1.52379018, 1.50962558, 1.51557709, 1.53210444]),\n",
       " 'test_mae': array([1.22004762, 1.22161062, 1.21556831, 1.21559523, 1.22851889]),\n",
       " 'fit_time': (0.07810473442077637,\n",
       "  0.09151077270507812,\n",
       "  0.14562129974365234,\n",
       "  0.09586668014526367,\n",
       "  0.13865423202514648),\n",
       " 'test_time': (0.15069293975830078,\n",
       "  0.09009027481079102,\n",
       "  0.1309680938720703,\n",
       "  0.09372830390930176,\n",
       "  0.14760613441467285)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import NormalPredictor\n",
    "random_algo = NormalPredictor()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(random_algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d240213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.5196\n",
      "MAE:  1.2151\n",
      "Running time:  0.15746688842773438\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "random_algo.fit(trainset)\n",
    "# Test the algorithm on the test set\n",
    "random_predict = random_algo.test(testset)\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute and print the RMSE and MAE scores\n",
    "rmse = accuracy.rmse(random_predict)\n",
    "mae = accuracy.mae(random_predict)\n",
    "print ('Running time: ', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f3035",
   "metadata": {},
   "source": [
    "3. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5f61d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.9789248208635446\n",
      "0.7729976466111383\n",
      "{'k': 40}\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "\n",
    "param_grid = {\"k\": [40, 80, 120, 160, 200]}\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=[\"rmse\", \"mae\"], cv=5)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE and MAE score\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_score[\"mae\"])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be0aaa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9733  0.9745  0.9754  0.9847  0.9841  0.9784  0.0049  \n",
      "MAE (testset)     0.7687  0.7715  0.7709  0.7773  0.7755  0.7728  0.0031  \n",
      "Fit time          0.44    0.47    0.47    0.45    0.45    0.46    0.01    \n",
      "Test time         3.36    3.30    3.32    3.22    3.29    3.30    0.05    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.97332174, 0.97445508, 0.97543347, 0.98467607, 0.9841351 ]),\n",
       " 'test_mae': array([0.7686914 , 0.77154319, 0.77093742, 0.7773245 , 0.77546492]),\n",
       " 'fit_time': (0.43740105628967285,\n",
       "  0.4686408042907715,\n",
       "  0.46863746643066406,\n",
       "  0.4530189037322998,\n",
       "  0.4530184268951416),\n",
       " 'test_time': (3.3554916381835938,\n",
       "  3.3029673099517822,\n",
       "  3.3231208324432373,\n",
       "  3.2188596725463867,\n",
       "  3.291860818862915)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_algo = KNNBasic(k=40)\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(knn_algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "540a066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9825\n",
      "MAE:  0.7762\n",
      "Running time:  3.7444703578948975\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "knn_algo.fit(trainset)\n",
    "# Test the algorithm on the test set\n",
    "knn_predict = knn_algo.test(testset)\n",
    "end_time = time.time()\n",
    "\n",
    "# Compute and print the RMSE and MAE scores\n",
    "rmse = accuracy.rmse(knn_predict)\n",
    "mae = accuracy.mae(knn_predict)\n",
    "print ('Running time: ', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a3118",
   "metadata": {},
   "source": [
    "4. Matrix Factorization with Regulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "255baafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the trainset to a numpy array\n",
    "trainset_np = np.zeros((trainset.n_users, trainset.n_items))\n",
    "for (uid, iid, rating) in trainset.all_ratings():\n",
    "    trainset_np[uid-1, iid-1] = rating\n",
    "\n",
    "# Convert the testset to a numpy array\n",
    "testset_np = np.zeros((len(testset), 3))\n",
    "# Iterate over the testset ratings and store them in the numpy array\n",
    "for i, (uid, iid, rating) in enumerate(testset):\n",
    "    testset_np[i, :] = [int(uid)-1, int(iid)-1, rating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3ed8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class MatrixFactorization:\n",
    "    def __init__(self, n_factors, n_epochs, lr, reg):\n",
    "        self.n_factors = n_factors\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "        \n",
    "    def fit(self, trainset):\n",
    "        # Initialize biases and latent factor matrices\n",
    "        self.global_bias = np.mean([r for (_, _, r) in trainset.all_ratings()])\n",
    "        self.user_bias = np.zeros(trainset.n_users)\n",
    "        self.item_bias = np.zeros(trainset.n_items)\n",
    "        self.user_mat = np.random.normal(size=(trainset.n_users, self.n_factors))\n",
    "        self.item_mat = np.random.normal(size=(trainset.n_items, self.n_factors))\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            # Update biases and latent factor matrices using training set\n",
    "            for (uid, iid, rating) in trainset.all_ratings():\n",
    "                # Predict rating\n",
    "                pred = self.test(uid, iid)\n",
    "                \n",
    "                # Calculate error\n",
    "                err = rating - pred\n",
    "                \n",
    "                # Update biases\n",
    "                self.global_bias += self.lr * err\n",
    "                self.user_bias[uid] += self.lr * (err - self.reg * self.user_bias[uid])\n",
    "                self.item_bias[iid] += self.lr * (err - self.reg * self.item_bias[iid])\n",
    "                \n",
    "                # Update latent factor matrices\n",
    "                self.user_mat[uid] += self.lr * (err * self.item_mat[iid] - self.reg * self.user_mat[uid])\n",
    "                self.item_mat[iid] += self.lr * (err * self.user_mat[uid] - self.reg * self.item_mat[iid])\n",
    "                \n",
    "            # Print RMSE on training set\n",
    "            train_preds = [self.test(uid, iid) for (uid, iid, _) in trainset.all_ratings()]\n",
    "            train_rmse = np.sqrt(np.mean([(r_ui - r_pred) ** 2 for (_, _, r_ui), r_pred in zip(trainset.all_ratings(), train_preds)]))\n",
    "            #print(\"Epoch\", epoch, \":\", \"train rmse =\", train_rmse)\n",
    "                \n",
    "    def test(self, uid, iid):\n",
    "        # Convert user and item IDs to integers\n",
    "        uid = int(uid)\n",
    "        iid = int(iid)\n",
    "        \n",
    "        if uid >= self.user_mat.shape[0] or iid >= self.item_mat.shape[0]:\n",
    "            return 3.0\n",
    "        \n",
    "        # Calculate predicted rating\n",
    "        pred = self.global_bias + self.user_bias[uid] + self.item_bias[iid] + np.dot(self.user_mat[uid], self.item_mat[iid])\n",
    "        \n",
    "        # Clip predicted rating to [1, 5] range\n",
    "        pred = np.clip(pred, 1, 5)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def calculate_rmse(self, testset):\n",
    "        rmse = 0\n",
    "        for (uid, iid, rating) in testset:\n",
    "            pred = self.test(uid, iid)\n",
    "            rmse += (rating - pred) ** 2\n",
    "        rmse = np.sqrt(rmse / len(testset))\n",
    "        return rmse\n",
    "    \n",
    "    def calculate_mae(self, testset):\n",
    "        mae = 0\n",
    "        for (uid, iid, rating) in testset:\n",
    "            pred = self.test(uid, iid)\n",
    "            mae += abs(rating - pred)\n",
    "        mae = mae / len(testset)\n",
    "        return mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17c9f70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9110555778704447\n",
      "0.7205422439812971\n",
      "{'n_factors': 200, 'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "param_grid = {'n_factors': [50, 100, 200],\n",
    "              'n_epochs': [10, 20, 30],\n",
    "              'lr_all': [0.001, 0.01, 0.1],\n",
    "              'reg_all': [0.001, 0.01, 0.1]}\n",
    "# Use SVD in hyperparameter tuning as alternative because SVD is a subcategory of Matrix Factorization\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=5)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE and MAE score\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_score[\"mae\"])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b750c60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.511873742425185\n",
      "MAE: 1.2016523866438047\n",
      "Running time:  180.71247673034668\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "mf_algo = MatrixFactorization(n_factors=200, n_epochs=30, lr=0.01, reg=0.1)\n",
    "mf_algo.fit(trainset)\n",
    "mf_predicts = [(uid, iid, r_ui, mf_algo.test(uid, iid)) for uid, iid, r_ui in testset]\n",
    "#mf_predict = [mf_algo.test(uid, iid) for (uid, iid, _) in testset]\n",
    "end_time = time.time()\n",
    "\n",
    "rmse = mf_algo.calculate_rmse(testset)\n",
    "mae = mf_algo.calculate_mae(testset)\n",
    "\n",
    "print('RMSE:', rmse)\n",
    "print('MAE:', mae)\n",
    "print ('Running time: ', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb72880",
   "metadata": {},
   "source": [
    "5. Deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1065bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "trainset_ratings = [{'user_id': r[0], 'item_id': r[1], 'rating': r[2]} for r in trainset.all_ratings()]\n",
    "trainset_df = pd.DataFrame(trainset_ratings, columns=['user_id', 'item_id', 'rating'])\n",
    "\n",
    "testset_ratings = [{'user_id': r[0], 'item_id': r[1], 'rating': r[2]} for r in testset]\n",
    "testset_df = pd.DataFrame(testset_ratings, columns=['user_id', 'item_id', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55e94a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "def create_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units1', min_value=32, max_value=512, step=32), activation='relu', input_shape=(2,)))\n",
    "    model.add(Dropout(hp.Float('dropout1', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp.Int('units2', min_value=32, max_value=256, step=32), activation='relu'))\n",
    "    model.add(Dropout(hp.Float('dropout2', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "815e087f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tuner_results\\neural_recommender\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    create_model,\n",
    "    objective='val_mean_absolute_error',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='tuner_results',\n",
    "    project_name='neural_recommender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b01bd812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    x=[trainset_df['user_id'], trainset_df['item_id']],\n",
    "    y=trainset_df['rating'],\n",
    "    epochs=10,\n",
    "    validation_data=(\n",
    "        [testset_df['user_id'], testset_df['item_id']],\n",
    "        testset_df['rating']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39d6a2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best units1: 512\n",
      "Best dropout1: 0.1\n",
      "Best units2: 128\n",
      "Best dropout2: 0.30000000000000004\n",
      "Best learning_rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "# Print out the best hyperparameters\n",
    "print(f\"Best units1: {best_hp.get('units1')}\")\n",
    "print(f\"Best dropout1: {best_hp.get('dropout1')}\")\n",
    "print(f\"Best units2: {best_hp.get('units2')}\")\n",
    "print(f\"Best dropout2: {best_hp.get('dropout2')}\")\n",
    "print(f\"Best learning_rate: {best_hp.get('learning_rate')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cbf36d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# Define the number of factors for the model\n",
    "n_factors = 50\n",
    "\n",
    "# Define the model architecture with the best hyperparameters\n",
    "dnn_algo = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(2,)),\n",
    "    Dropout(0.1),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# Compile the model with the specified loss function, optimizer, and metrics\n",
    "dnn_algo.compile(loss=root_mean_squared_error, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f1f19bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "41cd777c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80000, 2)\n",
      "y_train shape: (80000,)\n",
      "X_test shape: (20000, 2)\n",
      "y_test shape: (20000,)\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split as tts_surprise\n",
    "# Load the MovieLens 100K dataset\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "\n",
    "# Split the data into training and test sets\n",
    "trainset, testset = tts_surprise(data, test_size=0.2)\n",
    "\n",
    "# Convert the training and test data to numpy arrays\n",
    "X_train = np.array([(x[0], x[1]) for x in trainset.all_ratings()])\n",
    "y_train = np.array([x[2] for x in trainset.all_ratings()])\n",
    "X_test = np.array([(x[0], x[1]) for x in testset])\n",
    "y_test = np.array([x[2] for x in testset])\n",
    "\n",
    "# Print the shapes of the training and test data\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "794f11b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1193 - val_loss: 1.0981\n",
      "Epoch 2/50\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1186 - val_loss: 1.0995\n",
      "Epoch 3/50\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1187 - val_loss: 1.1025\n",
      "Epoch 4/50\n",
      "563/563 [==============================] - 3s 5ms/step - loss: 1.1190 - val_loss: 1.1012\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "RMSE: 1.1128241033207071\n",
      "MAE: 0.9356616813659668\n",
      "Running time:  13.352808713912964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "start_time = time.time()\n",
    "# Train the model on the training data\n",
    "history = dnn_algo.fit(X_train, y_train, batch_size=128, epochs=50,\n",
    "                       validation_split=0.1, callbacks=[early_stopping])\n",
    "# Use the trained model to make predictions on the test data\n",
    "X_test = X_test.astype('int32')\n",
    "dnn_predicts = dnn_algo.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE:\", mae)\n",
    "\n",
    "print ('Running time: ', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f852b876",
   "metadata": {},
   "source": [
    "Cross RMSE between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fb757d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9300\n",
      "SVD - Random RMSE =  0.9299628516573654\n",
      "RMSE: 0.9300\n",
      "SVD - kNN RMSE =  0.9299628516573654\n",
      "RMSE: 1.5196\n",
      "Random - kNN RMSE =  1.5196434977773465\n"
     ]
    }
   ],
   "source": [
    "rmse1 = accuracy.rmse(svd_predict, random_predict)\n",
    "print(\"SVD - Random RMSE = \", rmse1)\n",
    "rmse2 = accuracy.rmse(svd_predict, knn_predict)\n",
    "print(\"SVD - kNN RMSE = \", rmse2)\n",
    "rmse3 = accuracy.rmse(random_predict, knn_predict)\n",
    "print(\"Random - kNN RMSE = \", rmse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "005a4881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Factorization - Deep Neural Network =  1.043538010413047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mf_predicts_np_arr = np.array([x[3] for x in mf_predicts])\n",
    "rmse4 = np.sqrt(mean_squared_error(mf_predicts_np_arr, dnn_predicts.flatten()))\n",
    "print(\"Matrix Factorization - Deep Neural Network = \", rmse4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cf00f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual ratings\n",
    "random_predict_np_arr = np.array([pred.est for pred in random_predict])\n",
    "knn_predict_np_arr = np.array([pred.est for pred in knn_predict])\n",
    "svd_predict_np_arr = np.array([pred.est for pred in svd_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "63e9f193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Factorization - Random =  1.4345210804525301\n",
      "Matrix Factorization - kNN =  1.1512531272913682\n",
      "Matrix Factorization - SVD =  1.2030992517865915\n"
     ]
    }
   ],
   "source": [
    "rmse5 = np.sqrt(mean_squared_error(mf_predicts_np_arr, random_predict_np_arr))\n",
    "print(\"Matrix Factorization - Random = \", rmse5)\n",
    "rmse6 = np.sqrt(mean_squared_error(mf_predicts_np_arr, knn_predict_np_arr))\n",
    "print(\"Matrix Factorization - kNN = \", rmse6)\n",
    "rmse7 = np.sqrt(mean_squared_error(mf_predicts_np_arr, svd_predict_np_arr))\n",
    "print(\"Matrix Factorization - SVD = \", rmse7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "40903b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random - Deep Neural Network =  1.0335376833910799\n",
      "kNN - Deep Neural Network =  0.5761915233128835\n",
      "SVD - Deep Neural Network =  0.6782341744545051\n"
     ]
    }
   ],
   "source": [
    "rmse8 = np.sqrt(mean_squared_error(random_predict_np_arr, dnn_predicts.flatten()))\n",
    "print(\"Random - Deep Neural Network = \", rmse8)\n",
    "rmse9 = np.sqrt(mean_squared_error(knn_predict_np_arr, dnn_predicts.flatten()))\n",
    "print(\"kNN - Deep Neural Network = \", rmse9)\n",
    "rmse10 = np.sqrt(mean_squared_error(svd_predict_np_arr, dnn_predicts.flatten()))\n",
    "print(\"SVD - Deep Neural Network = \", rmse10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
